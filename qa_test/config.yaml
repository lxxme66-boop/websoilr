# 问答对质量评测系统配置文件

# 大语言模型配置
llm:
  # 提供商: openai, anthropic, local
  provider: local  # 改为使用本地大模型
  
  # API密钥（也可以通过环境变量设置）
  # api_key: your-api-key-here
  
  # 模型名称
  # OpenAI: gpt-4, gpt-3.5-turbo
  # Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
  # Local: 取决于你的本地模型
  model: qwen2.5:7b  # 本地模型示例
  
  # 生成参数
  temperature: 0.3
  max_tokens: 500
  
  # 是否启用缓存
  cache_enabled: true
  
  # 本地模型配置（当provider为local时使用）
  # API类型: ollama, vllm, openai-compatible
  api_type: ollama
  
  # 端点URL（如果不设置，将使用默认值）
  # Ollama默认: http://localhost:11434/api/chat
  # vLLM默认: http://localhost:8000/v1/chat/completions
  # endpoint_url: http://localhost:11434/api/chat
  
  # 请求超时时间（秒）
  timeout: 60
  
  # 可选：API密钥（某些本地服务可能需要）
  # api_key: your-local-api-key
  
  # 可选：自定义请求头
  # headers:
  #   X-Custom-Header: value

# 本地大模型配置示例
local_llm_examples:
  # Ollama配置示例
  ollama_example:
    provider: local
    api_type: ollama
    model: qwen2.5:7b  # 或 llama3.2:3b, deepseek-coder-v2:16b 等
    endpoint_url: http://localhost:11434/api/chat
    temperature: 0.3
    max_tokens: 500
  
  # vLLM配置示例
  vllm_example:
    provider: local
    api_type: vllm
    model: Qwen/Qwen2.5-7B-Instruct  # HuggingFace模型ID
    endpoint_url: http://localhost:8000/v1/chat/completions
    temperature: 0.3
    max_tokens: 500
  
  # FastChat配置示例
  fastchat_example:
    provider: local
    api_type: openai-compatible
    model: vicuna-7b-v1.5
    endpoint_url: http://localhost:8000/v1/chat/completions
    temperature: 0.3
    max_tokens: 500
  
  # LM Studio配置示例
  lm_studio_example:
    provider: local
    api_type: openai-compatible
    model: TheBloke/Llama-2-7B-Chat-GGUF
    endpoint_url: http://localhost:1234/v1/chat/completions
    temperature: 0.3
    max_tokens: 500

# 语义分析配置
semantic:
  # 预训练模型名称
  model_name: paraphrase-multilingual-MiniLM-L12-v2
  
  # 设备: cuda, cpu
  device: cpu
  
  # 是否启用缓存
  cache_enabled: true

# NLP指标配置
nlp:
  # 语言: chinese, english
  language: chinese
  
  # ROUGE评分类型
  rouge_types:
    - rouge1
    - rouge2
    - rougeL

# 数据预处理配置
preprocessing:
  # 是否去除HTML标签
  remove_html: true
  
  # 是否去除URLs
  remove_urls: true
  
  # 是否规范化空白字符
  normalize_whitespace: true
  
  # 是否去除特殊字符
  remove_special_chars: false
  
  # 文本长度限制
  min_length: 5
  max_length: 5000

# 评分权重配置
weights:
  relevance: 0.3
  completeness: 0.25
  accuracy: 0.25
  clarity: 0.2

# 文档感知评测配置
document_aware_evaluation:
  # 是否启用文档感知评测
  enabled: true
  
  # 是否使用LLM评估提取合理性
  use_llm_evaluation: true
  
  # 提取合理性评分权重
  extraction_weights:
    content_relevance: 0.25      # 内容相关性权重
    answer_grounding: 0.30       # 答案依据性权重
    question_specificity: 0.20   # 问题具体性权重
    information_completeness: 0.15  # 信息完整性权重
    llm_evaluation: 0.10         # LLM评估权重
  
  # TF-IDF向量化器配置
  tfidf_config:
    max_features: 5000
    ngram_range: [1, 2]
  
  # 相似度阈值
  similarity_thresholds:
    document_match: 0.5          # 文档匹配相似度阈值
    fallback_match: 0.3          # 回退匹配相似度阈值
  
  # 答案评估配置
  answer_evaluation:
    min_keyword_coverage: 0.6    # 最小关键词覆盖率
    min_answer_length: 20        # 最小答案长度
    max_answer_length: 500       # 最大答案长度
  
  # 问题评估配置
  question_evaluation:
    general_question_penalty: 0.7  # 通用问题惩罚系数

# 筛选阈值配置
thresholds:
  # 最低总分要求
  min_total_score: 0.7
  
  # 各维度最低分数要求
  min_llm_score: 0.6
  min_semantic_similarity: 0.5
  min_answer_quality: 0.5
  
  # 答案长度要求
  min_answer_length: 20
  max_answer_length: 1000

# 评测系统配置
evaluation:
  # 批处理大小
  batch_size: 10
  
  # 并行工作线程数
  max_workers: 4
  
  # 是否启用结果缓存
  cache_enabled: true

# 输出配置
output:
  # 输出格式: json, jsonl
  format: json
  
  # 是否生成详细报告
  generate_report: true
  
  # 报告包含的内容
  report_sections:
    - statistics
    - score_distribution
    - quality_insights
    - outliers
  
  # 是否保存评测详情
  save_details: true

# 日志配置
logging:
  # 日志级别: DEBUG, INFO, WARNING, ERROR
  level: INFO
  
  # 日志文件
  file: qa_evaluation.log
  
  # 是否在控制台输出
  console: true